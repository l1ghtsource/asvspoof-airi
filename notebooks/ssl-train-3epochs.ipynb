{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf83b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:05:21.555640Z",
     "iopub.status.busy": "2024-11-26T05:05:21.554894Z",
     "iopub.status.idle": "2024-11-26T05:05:25.683207Z",
     "shell.execute_reply": "2024-11-26T05:05:25.682229Z"
    },
    "papermill": {
     "duration": 4.135864,
     "end_time": "2024-11-26T05:05:25.685497",
     "exception": false,
     "start_time": "2024-11-26T05:05:21.549633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SSL_Anti-spoofing'...\r\n",
      "remote: Enumerating objects: 1579, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\r\n",
      "remote: Total 1579 (delta 52), reused 82 (delta 48), pack-reused 1489 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (1579/1579), 30.57 MiB | 23.43 MiB/s, done.\r\n",
      "Resolving deltas: 100% (293/293), done.\r\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "!git clone https://github.com/TakHemlata/SSL_Anti-spoofing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b06768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:05:25.695832Z",
     "iopub.status.busy": "2024-11-26T05:05:25.695543Z",
     "iopub.status.idle": "2024-11-26T05:05:25.702447Z",
     "shell.execute_reply": "2024-11-26T05:05:25.701705Z"
    },
    "papermill": {
     "duration": 0.013881,
     "end_time": "2024-11-26T05:05:25.704010",
     "exception": false,
     "start_time": "2024-11-26T05:05:25.690129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files and folders moved from /kaggle/working/SSL_Anti-spoofing to /kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_dir = '/kaggle/working/SSL_Anti-spoofing'\n",
    "destination_dir = '/kaggle/working/'\n",
    "\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "for item_name in os.listdir(source_dir):\n",
    "    source_item = os.path.join(source_dir, item_name)\n",
    "    destination_item = os.path.join(destination_dir, item_name)\n",
    "    \n",
    "    shutil.move(source_item, destination_item)\n",
    "\n",
    "print(f'All files and folders moved from {source_dir} to {destination_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966266dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:05:25.713155Z",
     "iopub.status.busy": "2024-11-26T05:05:25.712897Z",
     "iopub.status.idle": "2024-11-26T05:05:25.717908Z",
     "shell.execute_reply": "2024-11-26T05:05:25.717008Z"
    },
    "papermill": {
     "duration": 0.011317,
     "end_time": "2024-11-26T05:05:25.719453",
     "exception": false,
     "start_time": "2024-11-26T05:05:25.708136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py\"\n",
    "\n",
    "try:\n",
    "    os.remove(file_path)\n",
    "    print(f\"File {file_path} deleted successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file {file_path} does not exist.\")\n",
    "except PermissionError:\n",
    "    print(\"You do not have permission to delete this file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a47759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:05:25.729512Z",
     "iopub.status.busy": "2024-11-26T05:05:25.729297Z",
     "iopub.status.idle": "2024-11-26T05:05:25.763974Z",
     "shell.execute_reply": "2024-11-26T05:05:25.763214Z"
    },
    "papermill": {
     "duration": 0.041949,
     "end_time": "2024-11-26T05:05:25.765514",
     "exception": false,
     "start_time": "2024-11-26T05:05:25.723565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /kaggle/input/float32/indexed_dataset.py to /kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py\n"
     ]
    }
   ],
   "source": [
    "source_path = \"/kaggle/input/float32/indexed_dataset.py\"\n",
    "destination_path = \"/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/data/indexed_dataset.py\"\n",
    "\n",
    "shutil.copy2(source_path, destination_path)\n",
    "\n",
    "print(f'Copied {source_path} to {destination_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f9f27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:05:25.774666Z",
     "iopub.status.busy": "2024-11-26T05:05:25.774456Z",
     "iopub.status.idle": "2024-11-26T05:06:13.693856Z",
     "shell.execute_reply": "2024-11-26T05:06:13.692944Z"
    },
    "papermill": {
     "duration": 47.926259,
     "end_time": "2024-11-26T05:06:13.695912",
     "exception": false,
     "start_time": "2024-11-26T05:05:25.769653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (1.16.0)\r\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (3.0.10)\r\n",
      "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==1.0.0a0+4acaa61)\r\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting omegaconf<2.1 (from fairseq==1.0.0a0+4acaa61)\r\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (1.26.4)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (2024.5.15)\r\n",
      "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+4acaa61)\r\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (2.4.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (4.66.4)\r\n",
      "Collecting bitarray (from fairseq==1.0.0a0+4acaa61)\r\n",
      "  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\r\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+4acaa61) (2.4.0)\r\n",
      "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+4acaa61)\r\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4acaa61) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4acaa61) (4.12.2)\r\n",
      "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61)\r\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61) (0.9.0)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61) (0.4.6)\r\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4acaa61) (5.3.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq==1.0.0a0+4acaa61) (2.22)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (3.15.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+4acaa61) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq==1.0.0a0+4acaa61) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq==1.0.0a0+4acaa61) (1.3.0)\r\n",
      "Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\r\n",
      "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\r\n",
      "Building wheels for collected packages: fairseq, antlr4-python3-runtime\r\n",
      "  Building editable for fairseq (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-1.0.0a0+4acaa61-0.editable-cp310-cp310-linux_x86_64.whl size=9403 sha256=b1eae863123d5e5ce9357564b9ba904e4543d6d886e1d53b8acd962cfb1b690c\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6so55afd/wheels/35/08/f6/d9fd34bf105b76f5aa33c01c514418ef0f846fcd6bc17c20ee\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=cc27f55d61590e81c325fe73e1b6d17a3df067c1b723150c9feabb6595254a59\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\r\n",
      "Successfully built fairseq antlr4-python3-runtime\r\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, fairseq\r\n",
      "Successfully installed antlr4-python3-runtime-4.8 bitarray-3.0.0 fairseq-1.0.0a0+4acaa61 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-3.0.0 sacrebleu-2.4.3\r\n"
     ]
    }
   ],
   "source": [
    "!cd fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1 && pip install --editable ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b83589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:13.711455Z",
     "iopub.status.busy": "2024-11-26T05:06:13.711120Z",
     "iopub.status.idle": "2024-11-26T05:06:22.960565Z",
     "shell.execute_reply": "2024-11-26T05:06:22.959687Z"
    },
    "papermill": {
     "duration": 9.259241,
     "end_time": "2024-11-26T05:06:22.962510",
     "exception": false,
     "start_time": "2024-11-26T05:06:13.703269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.9.1 (from -r requirements.txt (line 2))\r\n",
      "  Downloading librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting tensorboardX==2.5 (from -r requirements.txt (line 3))\r\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: audioread>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (3.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.14.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.4.2)\r\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (5.1.1)\r\n",
      "Collecting resampy>=0.2.2 (from librosa==0.9.1->-r requirements.txt (line 2))\r\n",
      "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (0.60.0)\r\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (0.12.1)\r\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.8.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (21.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.5->-r requirements.txt (line 3)) (1.16.0)\r\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.5->-r requirements.txt (line 3)) (3.20.3)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.45.1->librosa==0.9.1->-r requirements.txt (line 2)) (0.43.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.1.2)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.11.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (2.32.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa==0.9.1->-r requirements.txt (line 2)) (3.5.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 2)) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 2)) (2.22)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (2024.8.30)\r\n",
      "Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: tensorboardX, resampy, librosa\r\n",
      "  Attempting uninstall: tensorboardX\r\n",
      "    Found existing installation: tensorboardX 2.6.2.2\r\n",
      "    Uninstalling tensorboardX-2.6.2.2:\r\n",
      "      Successfully uninstalled tensorboardX-2.6.2.2\r\n",
      "  Attempting uninstall: librosa\r\n",
      "    Found existing installation: librosa 0.10.2.post1\r\n",
      "    Uninstalling librosa-0.10.2.post1:\r\n",
      "      Successfully uninstalled librosa-0.10.2.post1\r\n",
      "Successfully installed librosa-0.9.1 resampy-0.4.3 tensorboardX-2.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5574cfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:22.979333Z",
     "iopub.status.busy": "2024-11-26T05:06:22.978629Z",
     "iopub.status.idle": "2024-11-26T05:06:59.082840Z",
     "shell.execute_reply": "2024-11-26T05:06:59.081880Z"
    },
    "papermill": {
     "duration": 36.114806,
     "end_time": "2024-11-26T05:06:59.085019",
     "exception": false,
     "start_time": "2024-11-26T05:06:22.970213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from data_utils_SSL import genSpoof_list,Dataset_ASVspoof2019_train,Dataset_ASVspoof2021_eval\n",
    "from model import Model\n",
    "from tensorboardX import SummaryWriter\n",
    "from core_scripts.startup_config import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e9459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:59.101959Z",
     "iopub.status.busy": "2024-11-26T05:06:59.101409Z",
     "iopub.status.idle": "2024-11-26T05:06:59.188018Z",
     "shell.execute_reply": "2024-11-26T05:06:59.187303Z"
    },
    "papermill": {
     "duration": 0.096818,
     "end_time": "2024-11-26T05:06:59.189677",
     "exception": false,
     "start_time": "2024-11-26T05:06:59.092859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler(device='cuda')\n",
    "\n",
    "def evaluate_accuracy(dev_loader, model, device, max_samples=None):\n",
    "    val_loss = 0.0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.1, 0.9]).to(device))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dev_loader:\n",
    "            batch_size = batch_x.size(0)\n",
    "            \n",
    "            if max_samples and num_total + batch_size > max_samples:\n",
    "                batch_size = int(max_samples - num_total)\n",
    "                batch_x = batch_x[:batch_size]\n",
    "                batch_y = batch_y[:batch_size]\n",
    "            \n",
    "            num_total += batch_size\n",
    "            \n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "            \n",
    "            batch_out = model(batch_x)\n",
    "            batch_loss = criterion(batch_out, batch_y)\n",
    "            \n",
    "            val_loss += (batch_loss.item() * batch_size)\n",
    "            \n",
    "            if max_samples and num_total >= max_samples:\n",
    "                break\n",
    "    \n",
    "    val_loss /= num_total\n",
    "    return val_loss\n",
    "\n",
    "def train_epoch(train_loader, model, optimizer, device):\n",
    "    running_loss = 0.0\n",
    "    num_total = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.1, 0.9]).to(device))\n",
    "    \n",
    "    batch_iterator = tqdm(train_loader, desc=\"Training\", leave=True)\n",
    "    for batch_x, batch_y in batch_iterator:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        \n",
    "        batch_x = batch_x.to(device, non_blocking=True)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast('cuda'):\n",
    "            batch_out = model(batch_x)\n",
    "            batch_loss = criterion(batch_out, batch_y)\n",
    "        \n",
    "        scaler.scale(batch_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += (batch_loss.item() * batch_size)\n",
    "        \n",
    "        batch_iterator.set_description(f\"Training - Batch Loss: {batch_loss.item():.4f}\")\n",
    "        \n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036285d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:59.205765Z",
     "iopub.status.busy": "2024-11-26T05:06:59.205499Z",
     "iopub.status.idle": "2024-11-26T05:06:59.211608Z",
     "shell.execute_reply": "2024-11-26T05:06:59.210842Z"
    },
    "papermill": {
     "duration": 0.015961,
     "end_time": "2024-11-26T05:06:59.213245",
     "exception": false,
     "start_time": "2024-11-26T05:06:59.197284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 3,\n",
    "    'lr': 0.000001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'loss': 'weighted_CCE',\n",
    "    'seed': 52,  # Random seed for reproducibility\n",
    "    'model_path': None,  # Path to a model checkpoint\n",
    "    'comment': None,  # Description for the saved model\n",
    "    'track': 'LA',  # Dataset track; options are 'LA', 'PA', 'DF'\n",
    "    'eval_output': None,  # Path to save evaluation results\n",
    "    'eval': False,  # Boolean for evaluation mode\n",
    "    'is_eval': False,  # Boolean for evaluation dataset\n",
    "    'eval_part': 0,  # Part of evaluation to process\n",
    "    'cudnn_deterministic_toggle': False,  # Use deterministic CuDNN behavior\n",
    "    'cudnn_benchmark_toggle': True,  # Use CuDNN benchmark for faster runtime\n",
    "    \n",
    "    # RawBoost data augmentation options\n",
    "    'algo': 4,  # RawBoost algorithm selection\n",
    "\n",
    "    # LnL_convolutive_noise parameters\n",
    "    'nBands': 5,  # Number of notch filters\n",
    "    'minF': 20,  # Minimum center frequency of notch filter\n",
    "    'maxF': 8000,  # Maximum center frequency of notch filter\n",
    "    'minBW': 100,  # Minimum bandwidth of filter\n",
    "    'maxBW': 1000,  # Maximum bandwidth of filter\n",
    "    'minCoeff': 10,  # Minimum filter coefficients\n",
    "    'maxCoeff': 100,  # Maximum filter coefficients\n",
    "    'minG': 0,  # Minimum gain factor of linear component\n",
    "    'maxG': 0,  # Maximum gain factor of linear component\n",
    "    'minBiasLinNonLin': 5,  # Minimum gain difference between linear/non-linear components\n",
    "    'maxBiasLinNonLin': 20,  # Maximum gain difference between linear/non-linear components\n",
    "    'N_f': 5,  # Order of non-linearity (1 means only linear)\n",
    "\n",
    "    # ISD_additive_noise parameters\n",
    "    'P': 10,  # Max number of uniformly distributed samples in [%]\n",
    "    'g_sd': 2,  # Gain parameter for additive noise\n",
    "\n",
    "    # SSI_additive_noise parameters\n",
    "    'SNRmin': 10,  # Minimum SNR for colored noise\n",
    "    'SNRmax': 40  # Maximum SNR for colored noise\n",
    "}\n",
    "\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5caf6de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:59.229001Z",
     "iopub.status.busy": "2024-11-26T05:06:59.228756Z",
     "iopub.status.idle": "2024-11-26T05:06:59.239012Z",
     "shell.execute_reply": "2024-11-26T05:06:59.238206Z"
    },
    "papermill": {
     "duration": 0.019861,
     "end_time": "2024-11-26T05:06:59.240550",
     "exception": false,
     "start_time": "2024-11-26T05:06:59.220689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn_deterministic set to False\n",
      "cudnn_benchmark set to True\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "set_random_seed(args.seed, args)\n",
    "track = args.track\n",
    "assert track in ['LA', 'PA','DF'], 'Invalid track given'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc487b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:59.256497Z",
     "iopub.status.busy": "2024-11-26T05:06:59.256246Z",
     "iopub.status.idle": "2024-11-26T05:06:59.273435Z",
     "shell.execute_reply": "2024-11-26T05:06:59.272766Z"
    },
    "papermill": {
     "duration": 0.026954,
     "end_time": "2024-11-26T05:06:59.274828",
     "exception": false,
     "start_time": "2024-11-26T05:06:59.247874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import fairseq\n",
    "\n",
    "class SSLModel(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(SSLModel, self).__init__()\n",
    "        \n",
    "        cp_path = '/kaggle/input/xlsr2-300m/xlsr2_300m.pt'\n",
    "        model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([cp_path])\n",
    "        self.model = model[0].to(device)\n",
    "        self.device = device\n",
    "        self.out_dim = 1024\n",
    "\n",
    "    def extract_feat(self, input_data):\n",
    "        input_data = input_data.to(self.device)\n",
    "        input_tmp = input_data[:, :, 0] if input_data.ndim == 3 else input_data\n",
    "        emb = self.model(input_tmp, mask=False, features_only=True)['x']\n",
    "        \n",
    "        return emb\n",
    "\n",
    "\n",
    "class PSFAN_Backend(nn.Module):\n",
    "    def __init__(self, input_channels=128, num_classes=2):\n",
    "        super(PSFAN_Backend, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_channels, 128, kernel_size=3, dilation=1, padding=1)\n",
    "        self.conv1x1_1 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.conv3x3_1 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv1x1_2 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.attention1 = nn.Sigmoid()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 128, kernel_size=3, dilation=2, padding=2)\n",
    "        self.conv1x1_3 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.conv3x3_2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv1x1_4 = nn.Conv1d(128, 128, kernel_size=1)\n",
    "        self.attention2 = nn.Sigmoid()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, dilation=3, padding=3)\n",
    "        self.conv1x1_5 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.conv3x3_3 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv1x1_6 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.attention3 = nn.Sigmoid()\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(256, 256, kernel_size=3, dilation=4, padding=4)\n",
    "        self.conv1x1_7 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.conv3x3_4 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv1x1_8 = nn.Conv1d(256, 256, kernel_size=1)\n",
    "        self.attention4 = nn.Sigmoid()\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.gap1 = nn.AdaptiveAvgPool1d(1)\n",
    "        self.gap2 = nn.AdaptiveAvgPool1d(1)\n",
    "        self.gap3 = nn.AdaptiveAvgPool1d(1)\n",
    "        self.gap4 = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.fc_concat = nn.Linear(128 + 128 + 256 + 256, 16)\n",
    "        self.fc_out = nn.Linear(16, num_classes)\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1_attention = self.attention1(self.conv1x1_1(self.conv3x3_1(self.conv1x1_2(x1))))\n",
    "        x1 = x1_attention * x1\n",
    "        x1 = self.pool1(x1)\n",
    "        x1_gap = self.gap1(x1).squeeze(-1)\n",
    "\n",
    "        x2 = self.conv2(x1)\n",
    "        x2_attention = self.attention2(self.conv1x1_3(self.conv3x3_2(self.conv1x1_4(x2))))\n",
    "        x2 = x2_attention * x2\n",
    "        x2 = self.pool2(x2)\n",
    "        x2_gap = self.gap2(x2).squeeze(-1)\n",
    "\n",
    "        x3 = self.conv3(x2)\n",
    "        x3_attention = self.attention3(self.conv1x1_5(self.conv3x3_3(self.conv1x1_6(x3))))\n",
    "        x3 = x3_attention * x3\n",
    "        x3 = self.pool3(x3)\n",
    "        x3_gap = self.gap3(x3).squeeze(-1)\n",
    "\n",
    "        x4 = self.conv4(x3)\n",
    "        x4_attention = self.attention4(self.conv1x1_7(self.conv3x3_4(self.conv1x1_8(x4))))\n",
    "        x4 = x4_attention * x4\n",
    "        x4 = self.pool4(x4)\n",
    "        x4_gap = self.gap4(x4).squeeze(-1)\n",
    "\n",
    "        x_concat = torch.cat([x1_gap, x2_gap, x3_gap, x4_gap], dim=1)\n",
    "\n",
    "        x = self.activation(self.fc_concat(x_concat))\n",
    "        output = self.fc_out(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, args, device):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.ssl_model = SSLModel(self.device)\n",
    "        self.LL = nn.Linear(self.ssl_model.out_dim, 128).to(device)\n",
    "        self.backend = PSFAN_Backend(input_channels=128, num_classes=2).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x_ssl_feat = self.ssl_model.extract_feat(x)\n",
    "        x = self.LL(x_ssl_feat)\n",
    "        x = x.transpose(1, 2)\n",
    "        output = self.backend(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01f1ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:59.290278Z",
     "iopub.status.busy": "2024-11-26T05:06:59.290009Z",
     "iopub.status.idle": "2024-11-26T05:07:42.557638Z",
     "shell.execute_reply": "2024-11-26T05:07:42.556954Z"
    },
    "papermill": {
     "duration": 43.277355,
     "end_time": "2024-11-26T05:07:42.559511",
     "exception": false,
     "start_time": "2024-11-26T05:06:59.282156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/checkpoint_utils.py:313: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_params: 318749618\n"
     ]
    }
   ],
   "source": [
    "model_tag = 'model_{}_{}_{}_{}_{}'.format(\n",
    "    track, args.loss, args.num_epochs, args.batch_size, args.lr)\n",
    "if args.comment:\n",
    "    model_tag = model_tag + '_{}'.format(args.comment)\n",
    "model_save_path = os.path.join('models', model_tag)\n",
    "\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "model = Model(args,device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "model = model.to(device)\n",
    "print('nb_params:',nb_params)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,weight_decay=args.weight_decay)\n",
    "\n",
    "if args.model_path:\n",
    "    model.load_state_dict(torch.load(args.model_path,map_location=device))\n",
    "    print('Model loaded : {}'.format(args.model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43834a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:07:42.576376Z",
     "iopub.status.busy": "2024-11-26T05:07:42.576074Z",
     "iopub.status.idle": "2024-11-26T05:08:30.653352Z",
     "shell.execute_reply": "2024-11-26T05:08:30.652426Z"
    },
    "papermill": {
     "duration": 48.09499,
     "end_time": "2024-11-26T05:08:30.662496",
     "exception": false,
     "start_time": "2024-11-26T05:07:42.567506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 318749618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3874279850.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model_path1 = '/kaggle/input/fed1-dev-and-train/fed1/epoch_2 (1).pth'\n",
    "model_path2 = '/kaggle/input/fed1-dev-and-train/fed1/epoch_2.pth'\n",
    "model_path3 = '/kaggle/input/fed1-test/epoch_1.pth'\n",
    "\n",
    "# i found this weight on kaggle, they gives 0.38 (just pretrain in asv2019 w/o dev&eval)\n",
    "\n",
    "model_tag = 'model_{}_{}_{}_{}_{}'.format(\n",
    "    track, args.loss, args.num_epochs, args.batch_size, args.lr)\n",
    "if args.comment:\n",
    "    model_tag = model_tag + '_{}'.format(args.comment)\n",
    "model_save_path = os.path.join('models', model_tag)\n",
    "\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.mkdir(model_save_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "model = Model(args, device).to(device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "print('nb_params:', nb_params)\n",
    "\n",
    "def load_model_weights(path, device):\n",
    "    if os.path.exists(path):\n",
    "        return torch.load(path, map_location=device)\n",
    "    else:\n",
    "        print(f\"Warning: Model path {path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "state_dict1 = load_model_weights(model_path1, device)\n",
    "state_dict2 = load_model_weights(model_path2, device)\n",
    "state_dict3 = load_model_weights(model_path3, device)\n",
    "\n",
    "if state_dict1 and state_dict2 and state_dict3:\n",
    "    aggregated_state_dict = {}\n",
    "    for key in state_dict1.keys():\n",
    "        aggregated_state_dict[key] = (state_dict1[key] + state_dict2[key] + state_dict3[key]) / 3.0\n",
    "    del state_dict1, state_dict2, state_dict3\n",
    "    model.load_state_dict(aggregated_state_dict)\n",
    "    del aggregated_state_dict\n",
    "    print(\"Aggregated model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: Failed to load weights from all clients. Check file paths.\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa00c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:08:30.678890Z",
     "iopub.status.busy": "2024-11-26T05:08:30.678350Z",
     "iopub.status.idle": "2024-11-26T05:08:30.946214Z",
     "shell.execute_reply": "2024-11-26T05:08:30.945337Z"
    },
    "papermill": {
     "duration": 0.27797,
     "end_time": "2024-11-26T05:08:30.947987",
     "exception": false,
     "start_time": "2024-11-26T05:08:30.670017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training trials 25380\n",
      "no. of dev trials 24844\n",
      "no. of validation trials 24844\n"
     ]
    }
   ],
   "source": [
    "d_label_trn, file_train = genSpoof_list(\n",
    "    dir_meta=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\",\n",
    "    is_train=True, is_eval=False)\n",
    "print('no. of training trials', len(file_train))\n",
    "\n",
    "train_set = Dataset_ASVspoof2019_train(\n",
    "    args, list_IDs=file_train, labels=d_label_trn,\n",
    "    base_dir=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/\",\n",
    "    algo=args.algo)\n",
    "\n",
    "d_label_dev, file_dev = genSpoof_list(\n",
    "    dir_meta=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\",\n",
    "    is_train=False, is_eval=False)\n",
    "print('no. of dev trials', len(file_dev))\n",
    "\n",
    "dev_set = Dataset_ASVspoof2019_train(\n",
    "    args, list_IDs=file_dev, labels=d_label_dev,\n",
    "    base_dir=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_dev/\",\n",
    "    algo=args.algo)\n",
    "\n",
    "d_label_eval, file_eval = genSpoof_list(\n",
    "    dir_meta=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\",\n",
    "    is_train=False, is_eval=False)\n",
    "print('no. of validation trials', len(file_dev))\n",
    "\n",
    "eval_set = Dataset_ASVspoof2019_train(\n",
    "    args, list_IDs=file_eval, labels=d_label_eval,\n",
    "    base_dir=\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/\",\n",
    "    algo=args.algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0d6c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:08:30.965813Z",
     "iopub.status.busy": "2024-11-26T05:08:30.965278Z",
     "iopub.status.idle": "2024-11-26T05:08:30.969799Z",
     "shell.execute_reply": "2024-11-26T05:08:30.969139Z"
    },
    "papermill": {
     "duration": 0.014859,
     "end_time": "2024-11-26T05:08:30.971404",
     "exception": false,
     "start_time": "2024-11-26T05:08:30.956545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "combined_dataset = ConcatDataset([train_set, dev_set, eval_set])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    combined_dataset, batch_size=args.batch_size, num_workers=4, shuffle=True,\n",
    "    drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578777f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:08:30.988144Z",
     "iopub.status.busy": "2024-11-26T05:08:30.987526Z",
     "iopub.status.idle": "2024-11-26T11:16:26.585786Z",
     "shell.execute_reply": "2024-11-26T11:16:26.584721Z"
    },
    "papermill": {
     "duration": 22075.608987,
     "end_time": "2024-11-26T11:16:26.588113",
     "exception": false,
     "start_time": "2024-11-26T05:08:30.979126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/7591 [00:00<?, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training - Batch Loss: 0.0005: 100%|██████████| 7591/7591 [2:03:23<00:00,  1.07it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training - Batch Loss: 0.0005: 100%|██████████| 7591/7591 [2:03:23<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Batch Loss: 0.0001: 100%|██████████| 7591/7591 [2:02:04<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Batch Loss: 0.0001: 100%|██████████| 7591/7591 [2:02:22<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = args.num_epochs\n",
    "writer = SummaryWriter('logs/{}'.format(model_tag))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch {}'.format(epoch))\n",
    "    \n",
    "    running_loss = train_epoch(train_loader, model, optimizer, device)\n",
    "    writer.add_scalar('loss', running_loss, epoch)\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(model_save_path, f'epoch_{epoch}.pth'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2286778,
     "sourceId": 3842332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4827121,
     "sourceId": 8452149,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5952420,
     "sourceId": 9727510,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5968457,
     "sourceId": 9748923,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6056164,
     "sourceId": 9866535,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6058514,
     "sourceId": 9869755,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22273.853059,
   "end_time": "2024-11-26T11:16:32.643523",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T05:05:18.790464",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
